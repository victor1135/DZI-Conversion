# 性能瓶頸分析

## 整個流程的三個主要階段

### 1. 📤 **文件上傳階段** (main.py:158-160)
**可能的瓶頸：**
- `content = await file.read()` - **一次性讀取整個文件到內存**
  - 對於 800MB SVS 文件，會佔用 800MB+ 內存
  - 如果內存不足，可能導致交換（swap），速度變慢
  - **影響：** 中等（取決於內存大小）

**優化建議：**
- 使用流式上傳（chunked upload）
- 邊讀邊寫，不一次性加載到內存

---

### 2. 🔄 **DZI 轉換階段** (dzi_converter.py:209-225)
**可能的瓶頸（按影響程度排序）：**

#### ⚠️ **最大瓶頸：`image.dzsave()` 生成瓦片**
- **位置：** `dzi_converter.py:219-225`
- **耗時原因：**
  - 需要讀取整個 SVS 文件（可能幾 GB）
  - 生成多個層級（9 層 = 9 個縮放級別）
  - 每個層級需要切分成數百到數千個瓦片
  - 每個瓦片需要 JPEG 編碼
  - **總瓦片數：** 對於 800MB SVS，可能有 5000-10000+ 個瓦片文件
- **影響：** ⭐⭐⭐⭐⭐ **最耗時的部分**
- **典型時間：** 800MB SVS 可能需要 10-30 分鐘（取決於 CPU 和磁盤速度）

#### ⚠️ **次要瓶頸：`pyvips.Image.new_from_file()`**
- **位置：** `dzi_converter.py:209`
- **耗時原因：**
  - 需要解析 SVS 文件格式
  - 讀取文件元數據
  - 初始化圖像對象
- **影響：** ⭐⭐⭐ 中等（通常幾秒到幾十秒）

#### ⚠️ **次要瓶頸：磁盤 I/O**
- **位置：** 整個轉換過程
- **耗時原因：**
  - 寫入數千個小文件（每個瓦片 5-50KB）
  - 如果使用機械硬盤（HDD），隨機寫入會很慢
  - SSD 會快很多
- **影響：** ⭐⭐⭐⭐ 高（取決於存儲類型）

**優化建議：**
- 使用 SSD 而不是 HDD
- 增加 CPU 核心數（libvips 支持多線程）
- 考慮使用更快的存儲（NVMe SSD）

---

### 3. ☁️ **上傳到 S3 階段** (cloud_storage.py:147-263)
**可能的瓶頸（按影響程度排序）：**

#### ⚠️ **最大瓶頸：網絡帶寬**
- **位置：** 整個上傳過程
- **耗時原因：**
  - 需要上傳數千個小文件（每個文件一個 HTTP 請求）
  - 即使並行上傳，總數據量仍然很大
  - 網絡延遲（latency）對小文件影響大
- **影響：** ⭐⭐⭐⭐⭐ **最耗時的部分（如果網絡慢）**
- **典型時間：** 
  - 100Mbps 網絡：約 1-2 小時（5000 個文件）
  - 1Gbps 網絡：約 10-20 分鐘
  - 10Gbps 網絡：約 1-2 分鐘

#### ⚠️ **次要瓶頸：並行度不足**
- **位置：** `cloud_storage.py:219` - `max_workers=20`
- **當前狀態：** 已優化到 20 個並行上傳
- **影響：** ⭐⭐ 低（已優化）

#### ⚠️ **次要瓶頸：S3 API 限制**
- **位置：** S3 服務端
- **耗時原因：**
  - S3 有請求速率限制（雖然通常不會達到）
  - 每個請求都有開銷（HTTP headers, authentication）
- **影響：** ⭐⭐ 低（通常不是問題）

**優化建議：**
- 增加網絡帶寬
- 考慮使用 S3 Transfer Acceleration
- 可以進一步增加並行度（但要注意 S3 限制）

---

## 📊 時間分配估算（800MB SVS 文件）

假設：
- CPU: 4 核心
- 存儲: SSD
- 網絡: 100Mbps

| 階段 | 時間 | 佔比 | 瓶頸 |
|------|------|------|------|
| 1. 文件上傳到服務器 | 1-2 分鐘 | 5% | 網絡帶寬（前端→後端） |
| 2. DZI 轉換 | 15-25 分鐘 | 60% | CPU + 磁盤 I/O |
| 3. 上傳到 S3 | 60-120 分鐘 | 35% | 網絡帶寬（後端→S3） |
| **總計** | **76-147 分鐘** | **100%** | |

---

## 🔍 如何診斷瓶頸

### 檢查轉換階段是否慢：
```python
# 在 dzi_converter.py 添加時間記錄
import time
start = time.time()
image.dzsave(...)
print(f"[PERF] DZI conversion took: {time.time() - start:.2f} seconds")
```

### 檢查上傳階段是否慢：
```python
# 在 cloud_storage.py 添加時間記錄
import time
start = time.time()
# ... 上傳邏輯 ...
print(f"[PERF] Upload took: {time.time() - start:.2f} seconds")
print(f"[PERF] Average speed: {total_size / (time.time() - start) / 1024 / 1024:.2f} MB/s")
```

### 檢查系統資源：
- **CPU 使用率：** 如果 < 50%，可能是 I/O 瓶頸
- **磁盤 I/O：** 如果磁盤使用率 100%，是磁盤瓶頸
- **網絡使用率：** 如果網絡使用率 < 帶寬，可能是並行度不足

---

## 🚀 優化優先級

### 高優先級（影響最大）：
1. **使用 SSD 存儲** - 可以將轉換時間減少 50-70%
2. **增加網絡帶寬** - 可以將上傳時間減少 50-90%
3. **使用更快的 CPU** - 可以將轉換時間減少 20-40%

### 中優先級：
4. **增加並行度** - 已優化到 20，可以嘗試 30-50（但要注意限制）
5. **使用 S3 Transfer Acceleration** - 可以減少 20-30% 上傳時間

### 低優先級：
6. **流式文件上傳** - 減少內存使用，但對速度影響小
7. **壓縮瓦片** - 減少上傳數據量，但增加 CPU 使用

---

## 💡 快速診斷命令

```bash
# 檢查 CPU 使用率
# Windows: 任務管理器
# Linux: top 或 htop

# 檢查磁盤 I/O
# Windows: 資源監視器
# Linux: iostat -x 1

# 檢查網絡速度
# 測試上傳速度到 S3
aws s3 cp test.bin s3://your-bucket/test.bin --profile your-profile
```
